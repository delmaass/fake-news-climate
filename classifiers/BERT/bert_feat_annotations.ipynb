{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ba3262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "import seaborn\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from transformers import CamembertForSequenceClassification, CamembertTokenizer, AutoConfig, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, random_split, \\\n",
    "                            DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ec8e94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: (50, 6)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "# features = np.array(pickle.load(open(\"features.p\", \"rb\")), dtype=object)\n",
    "# labels = np.array(pickle.load(open(\"labels.p\", \"rb\")), dtype=object)\n",
    "# docs = np.array(pickle.load(open(\"docs.p\", \"rb\")), dtype=object)\n",
    "\n",
    "#docs_train = np.array(pickle.load(open(\"docs_train.p\", \"rb\")), dtype=object)\n",
    "#docs_test = np.array(pickle.load(open(\"docs_test.p\", \"rb\")), dtype=object)\n",
    "#docs_val = np.array(pickle.load(open(\"docs_val.p\", \"rb\")), dtype=object)\n",
    "\n",
    "#features_train = np.array(pickle.load(open(\"features_train.p\", \"rb\")), dtype=object)\n",
    "#features_test = np.array(pickle.load(open(\"features_test.p\", \"rb\")), dtype=object)\n",
    "#features_validation = np.array(pickle.load(open(\"features_val.p\", \"rb\")), dtype=object)\n",
    "\n",
    "#labels_train = np.array(pickle.load(open(\"labels_train.p\", \"rb\")), dtype=object)\n",
    "#labels_test = np.array(pickle.load(open(\"labels_test.p\", \"rb\")), dtype=object)\n",
    "#labels_validation = np.array(pickle.load(open(\"labels_val.p\", \"rb\")), dtype=object)\n",
    "\n",
    "\n",
    "\n",
    "docs = np.array([\"ceci est une fake news\"]*50).reshape((50, 1))\n",
    "labels = np.array([2]*10 + [1]*15 + [0]*25).reshape((50, 1))\n",
    "features = np.ones((50, 4)).astype(\"float\")\n",
    "\n",
    "dataset = np.hstack((labels, docs, features))\n",
    "\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "print(f'Dataset: {dataset.shape}')\n",
    "\n",
    "labels = np.array(dataset[:, 0], dtype=int) # - 1\n",
    "docs = dataset[:, 1]\n",
    "features = np.array(dataset[:, 2:], dtype = np.float32)\n",
    "print(features.dtype)\n",
    "\n",
    "\n",
    "num_extra_dims = np.shape(features)[1]\n",
    "num_labels = len(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8362953a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 25, 1: 15, 2: 10})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4af158b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6667, 1.1111, 1.6667])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulmeddeb/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1 2], y=[2 2 1 1 0 0 1 0 0 0 0 2 2 0 1 1 1 2 0 1 0 2 0 1 2 0 0 1 2 0 1 0 0 0 0 1 0\n",
      " 1 1 1 0 2 2 0 0 0 0 0 0 1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "class_weights=class_weight.compute_class_weight('balanced',np.unique(labels),labels)\n",
    "class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
    " \n",
    "print(class_weights) #([1.0000, 1.0000, 4.0000, 1.0000, 0.5714])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f6b2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER = CamembertTokenizer.from_pretrained(\n",
    "    'camembert-base',\n",
    "    do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1788dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_spacy(docs, pos=[\"PUNCT\", \"ADV\", \"ADJ\", \"VERB\", \"NOUN\"]):\n",
    "    texts = [\" \".join([token.text for token in doc if not token.is_stop and token.pos_ in pos]) for doc in docs]\n",
    "\n",
    "    return texts\n",
    "\n",
    "def preprocess(raw_articles, features = None, labels=None):\n",
    "    \"\"\"\n",
    "        Create pytorch dataloader from raw data\n",
    "    \"\"\"\n",
    "\n",
    "    # https://huggingface.co/docs/transformers/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_encode_plus.truncation\n",
    "\n",
    "    encoded_batch = TOKENIZER.batch_encode_plus(raw_articles,\n",
    "                                                add_special_tokens=False,\n",
    "                                                padding = True,\n",
    "                                                truncation = True,\n",
    "                                                max_length = 512,\n",
    "                                                return_attention_mask=True,\n",
    "                                                return_tensors = 'pt')\n",
    "        \n",
    "\n",
    "    if features is not None:\n",
    "        features = torch.tensor(features)\n",
    "        if labels is not None:\n",
    "            labels = torch.tensor(labels)\n",
    "            return encoded_batch['input_ids'], encoded_batch['attention_mask'], features, labels\n",
    "        return encoded_batch['input_ids'], encoded_batch['attention_mask'], features\n",
    "    \n",
    "    else :\n",
    "        if labels is not None:\n",
    "            labels = torch.tensor(labels)\n",
    "            return encoded_batch['input_ids'], encoded_batch['attention_mask'], labels\n",
    "        return encoded_batch['input_ids'], encoded_batch['attention_mask']\n",
    "        \n",
    "\n",
    "articles = docs #to comment !\n",
    "#articles_train, articles_test, articles_validation = preprocess_spacy(docs_train), preprocess_spacy(docs_test), preprocess_spacy(docs_val)\n",
    "#print(TOKENIZER.convert_ids_to_tokens(preprocess(articles, features = features, labels=labels)[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29732b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train-validation to-comment !!\n",
    "split_border = int(len(labels)*0.8)\n",
    "articles_train, articles_validation = articles[:split_border], articles[split_border:]\n",
    "features_train, features_validation = features[:split_border], features[split_border:]\n",
    "labels_train, labels_validation = labels[:split_border], labels[split_border:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfc6593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, attention_mask, features_train, labels_train = preprocess(articles_train, features_train, labels_train)\n",
    "# Combine the training inputs into a TensorDataset\n",
    "train_dataset = TensorDataset(\n",
    "    input_ids,\n",
    "    attention_mask,\n",
    "    features_train,\n",
    "    labels_train)\n",
    "    \n",
    "\n",
    "input_ids, attention_mask, features_validation, labels_validation = preprocess(articles_validation, features_validation, labels_validation)\n",
    "# Combine the validation inputs into a TensorDataset\n",
    "validation_dataset = TensorDataset(\n",
    "    input_ids,\n",
    "    attention_mask,\n",
    "    features_validation,\n",
    "    labels_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df7dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
