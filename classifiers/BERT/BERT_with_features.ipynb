{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e03549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "import seaborn\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from transformers import CamembertForSequenceClassification, CamembertTokenizer, AutoConfig, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, random_split, \\\n",
    "                            DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f46080a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: (50, 6)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "# features = np.array(pickle.load(open(\"features.p\", \"rb\")), dtype=object)\n",
    "# labels = np.array(pickle.load(open(\"labels.p\", \"rb\")), dtype=object)\n",
    "# docs = np.array(pickle.load(open(\"docs.p\", \"rb\")), dtype=object)\n",
    "\n",
    "#docs_train = np.array(pickle.load(open(\"docs_train.p\", \"rb\")), dtype=object)\n",
    "#docs_test = np.array(pickle.load(open(\"docs_test.p\", \"rb\")), dtype=object)\n",
    "#docs_val = np.array(pickle.load(open(\"docs_val.p\", \"rb\")), dtype=object)\n",
    "\n",
    "#features_train = np.array(pickle.load(open(\"features_train.p\", \"rb\")), dtype=object)\n",
    "#features_test = np.array(pickle.load(open(\"features_test.p\", \"rb\")), dtype=object)\n",
    "#features_validation = np.array(pickle.load(open(\"features_val.p\", \"rb\")), dtype=object)\n",
    "\n",
    "#labels_train = np.array(pickle.load(open(\"labels_train.p\", \"rb\")), dtype=object)\n",
    "#labels_test = np.array(pickle.load(open(\"labels_test.p\", \"rb\")), dtype=object)\n",
    "#labels_validation = np.array(pickle.load(open(\"labels_val.p\", \"rb\")), dtype=object)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "docs = np.array([\"ceci est une fake news\"]*50).reshape((50, 1))\n",
    "labels = np.array([2]*10 + [1]*15 + [0]*25).reshape((50, 1))\n",
    "features = np.ones((50, 4)).astype(\"float\")\n",
    "\n",
    "dataset = np.hstack((labels, docs, features))\n",
    "\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "print(f'Dataset: {dataset.shape}')\n",
    "\n",
    "labels = np.array(dataset[:, 0], dtype=int) # - 1\n",
    "docs = dataset[:, 1]\n",
    "features = np.array(dataset[:, 2:], dtype = np.float32)\n",
    "print(features.dtype)\n",
    "\n",
    "\n",
    "num_extra_dims = np.shape(features)[1]\n",
    "num_labels = len(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61f3edf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 25, 1: 15, 2: 10})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5fbabd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6667, 1.1111, 1.6667])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulmeddeb/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1 2], y=[1 1 1 0 0 0 1 0 1 0 2 2 2 0 0 0 0 1 0 1 2 0 0 2 1 2 0 0 0 1 1 1 2 1 0 0 0\n",
      " 0 2 1 0 2 0 1 1 0 2 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "class_weights=class_weight.compute_class_weight('balanced',np.unique(labels),labels)\n",
    "class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
    " \n",
    "print(class_weights) #([1.0000, 1.0000, 4.0000, 1.0000, 0.5714])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5362da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER = CamembertTokenizer.from_pretrained(\n",
    "    'camembert-base',\n",
    "    do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63d246de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_spacy(docs, pos=[\"PUNCT\", \"ADV\", \"ADJ\", \"VERB\", \"NOUN\"]):\n",
    "    texts = [\" \".join([token.text for token in doc if not token.is_stop and token.pos_ in pos]) for doc in docs]\n",
    "\n",
    "    return texts\n",
    "\n",
    "def preprocess(raw_articles, features = None, labels=None):\n",
    "    \"\"\"\n",
    "        Create pytorch dataloader from raw data\n",
    "    \"\"\"\n",
    "\n",
    "    # https://huggingface.co/docs/transformers/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_encode_plus.truncation\n",
    "\n",
    "    encoded_batch = TOKENIZER.batch_encode_plus(raw_articles,\n",
    "                                                add_special_tokens=False,\n",
    "                                                padding = True,\n",
    "                                                truncation = True,\n",
    "                                                max_length = 512,\n",
    "                                                return_attention_mask=True,\n",
    "                                                return_tensors = 'pt')\n",
    "        \n",
    "\n",
    "    if features is not None:\n",
    "        features = torch.tensor(features)\n",
    "        if labels is not None:\n",
    "            labels = torch.tensor(labels)\n",
    "            return encoded_batch['input_ids'], encoded_batch['attention_mask'], features, labels\n",
    "        return encoded_batch['input_ids'], encoded_batch['attention_mask'], features\n",
    "    \n",
    "    else :\n",
    "        if labels is not None:\n",
    "            labels = torch.tensor(labels)\n",
    "            return encoded_batch['input_ids'], encoded_batch['attention_mask'], labels\n",
    "        return encoded_batch['input_ids'], encoded_batch['attention_mask']\n",
    "        \n",
    "\n",
    "articles = docs #to comment !\n",
    "#articles_train, articles_test, articles_validation = preprocess_spacy(docs_train), preprocess_spacy(docs_test), preprocess_spacy(docs_val)\n",
    "#print(TOKENIZER.convert_ids_to_tokens(preprocess(articles, features = features, labels=labels)[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50868f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train-validation to-comment !!\n",
    "split_border = int(len(labels)*0.8)\n",
    "articles_train, articles_validation = articles[:split_border], articles[split_border:]\n",
    "features_train, features_validation = features[:split_border], features[split_border:]\n",
    "labels_train, labels_validation = labels[:split_border], labels[split_border:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0f561c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, attention_mask, features_train, labels_train = preprocess(articles_train, features_train, labels_train)\n",
    "# Combine the training inputs into a TensorDataset\n",
    "train_dataset = TensorDataset(\n",
    "    input_ids,\n",
    "    attention_mask,\n",
    "    features_train,\n",
    "    labels_train)\n",
    "    \n",
    "\n",
    "input_ids, attention_mask, features_validation, labels_validation = preprocess(articles_validation, features_validation, labels_validation)\n",
    "# Combine the validation inputs into a TensorDataset\n",
    "validation_dataset = TensorDataset(\n",
    "    input_ids,\n",
    "    attention_mask,\n",
    "    features_validation,\n",
    "    labels_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb32851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset),\n",
    "            batch_size = batch_size)\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            validation_dataset,\n",
    "            sampler = SequentialSampler(validation_dataset),\n",
    "            batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eda3241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This takes a transformer backbone and puts a slightly-modified classification head on top.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name, num_extra_dims, num_labels):\n",
    "        # num_extra_dims corresponds to the number of extra dimensions of numerical/categorical data\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = AutoConfig.from_pretrained(model_name)\n",
    "        self.transformer = AutoModel.from_pretrained(model_name, config=self.config)\n",
    "        num_hidden_size = self.transformer.config.hidden_size # May be different depending on which model you use. Common sizes are 768 and 1024. Look in the config.json file \n",
    "        self.classifier = torch.nn.Linear(num_hidden_size+num_extra_dims, num_labels)\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, extra_data, attention_mask=None):\n",
    "        \"\"\"\n",
    "        extra_data should be of shape [batch_size, dim] \n",
    "        where dim is the number of additional numerical/categorical dimensions\n",
    "        \"\"\"\n",
    "\n",
    "        hidden_states = self.transformer(input_ids=input_ids, attention_mask=attention_mask) # [batch size, sequence length, hidden size]\n",
    "\n",
    "        cls_embeds = hidden_states[0][:, 0, :] # [batch size, hidden size]\n",
    "\n",
    "        concat = torch.cat((cls_embeds, extra_data), dim=-1) # [batch size, hidden size+num extra dims]\n",
    "\n",
    "        output = self.classifier(concat) # [batch size, num labels]\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64aeba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"camembert-base\"\n",
    "model = CustomModel(model_name, num_extra_dims=num_extra_dims, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "121d5b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-9ba8d58322e6>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.tensor(features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "def predict(articles, features, model=model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        input_ids, attention_mask, extra_data = preprocess(articles, features)\n",
    "        output = model(input_ids, extra_data, attention_mask=attention_mask)\n",
    "        return torch.argmax(output, dim=1)\n",
    "print(predict(articles_train[:10], features_train[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d83c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(articles, features, labels, metric='report'):\n",
    "    predictions = predict(articles, features)\n",
    "    if metric == 'report':\n",
    "        return metrics.classification_report(labels, predictions, zero_division=0)\n",
    "    elif metric == 'matrix':\n",
    "        return metrics.confusion_matrix(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc86c062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c66d0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # Learning Rate - Default is 5e-5\n",
    "                  eps = 1e-8 # Adam Epsilon  - Default is 1e-8.\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9d8395e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## Epoch 0 / 12 ##########\n",
      "Training...\n",
      "test time\n",
      "step : 0\n",
      "tensor(1.1022, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulmeddeb/opt/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
      "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 1\n",
      "tensor(1.1134, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "  Average training loss: 1.11\n",
      "  Training epoch took: 3.3993921279907227\n",
      "\n",
      "########## Epoch 1 / 12 ##########\n",
      "Training...\n",
      "test time\n",
      "step : 0\n",
      "tensor(1.1059, grad_fn=<NllLossBackward0>)\n",
      "step : 1\n",
      "tensor(1.1020, grad_fn=<NllLossBackward0>)\n",
      "Model saved!\n",
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epoch took: 2.8495922088623047\n",
      "\n",
      "########## Epoch 2 / 12 ##########\n",
      "Training...\n",
      "test time\n",
      "step : 0\n",
      "tensor(1.1078, grad_fn=<NllLossBackward0>)\n",
      "step : 1\n",
      "tensor(1.0826, grad_fn=<NllLossBackward0>)\n",
      "Model saved!\n",
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epoch took: 2.869687795639038\n",
      "\n",
      "########## Epoch 3 / 12 ##########\n",
      "Training...\n",
      "test time\n",
      "step : 0\n",
      "tensor(1.0927, grad_fn=<NllLossBackward0>)\n",
      "step : 1\n",
      "tensor(1.1077, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epoch took: 2.364192008972168\n",
      "\n",
      "########## Epoch 4 / 12 ##########\n",
      "Training...\n",
      "test time\n",
      "step : 0\n",
      "tensor(1.1064, grad_fn=<NllLossBackward0>)\n",
      "step : 1\n",
      "tensor(1.0893, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epoch took: 2.3457727432250977\n",
      "Stop training : The loss has not changed since 2 epochs!\n"
     ]
    }
   ],
   "source": [
    "SAVE_PATH = \"customed_camembert_model.model\"\n",
    "\n",
    "# Training loop\n",
    "training_stats = []\n",
    "                                                                                \n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "epochs = 12\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]\n",
    "# (Note that this is not the same as the number of training samples)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights,reduction='mean').to(device)\n",
    "\n",
    "# This variable will evaluate the convergence on the training\n",
    "consecutive_epochs_with_no_improve = 0\n",
    "\n",
    "# Training\n",
    "for epoch in range(0, epochs):\n",
    "    \n",
    "    print(\"\")\n",
    "    print(f'########## Epoch {epoch} / {epochs} ##########')\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    print('test time')\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        print(f'step : {step}')\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = time.time() - t0\n",
    "            \n",
    "            # Report progress\n",
    "            print(f'  Batch {step}  of  {len(train_dataloader)}    Elapsed: {format_time(elapsed)}.')\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the 'device' using the 'to' method\n",
    "        #\n",
    "        # 'batch' contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: skills \n",
    "        input_id = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        feature = batch[2].to(device)\n",
    "        label = batch[3].to(device)\n",
    "\n",
    "        # Clear any previously calculated gradients before performing a backward pass\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch)\n",
    "        # the loss (because we provided skills) and the \"logits\"--the model\n",
    "        # outputs prior to activation\n",
    "        logits = model(input_id,\n",
    "                       feature, \n",
    "                       attention_mask=attention_mask)\n",
    "        \n",
    "        loss = criterion(logits, label)\n",
    "        print(loss)\n",
    "\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. 'loss' is a Tensor containing a\n",
    "        # single value; the '.item()' function just returns the Python value \n",
    "        # from the tensor\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)   \n",
    "\n",
    "    if epoch > 0:\n",
    "        if min([stat['Training Loss'] for stat in training_stats]) <= avg_train_loss:\n",
    "            # i.e. If there is not improvement\n",
    "            consecutive_epochs_with_no_improve += 1\n",
    "        else:\n",
    "            # If there is improvement\n",
    "            consecutive_epochs_with_no_improve = 0\n",
    "            print(\"Model saved!\")\n",
    "            torch.save(model.state_dict(), SAVE_PATH)\n",
    "    \n",
    "    # Measure how long this epoch took\n",
    "    training_time = time.time() - t0\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "    \n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Training Time': training_time,\n",
    "        }\n",
    "    )\n",
    "    if consecutive_epochs_with_no_improve == 2:\n",
    "        print(\"Stop training : The loss has not changed since 2 epochs!\")\n",
    "        break\n",
    "        \n",
    "torch.save(model.state_dict(), SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1a4c3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-9ba8d58322e6>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.tensor(features)\n",
      "<ipython-input-43-9ba8d58322e6>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.tensor(features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.20      1.00      0.33         2\n",
      "\n",
      "    accuracy                           0.20        10\n",
      "   macro avg       0.07      0.33      0.11        10\n",
      "weighted avg       0.04      0.20      0.07        10\n",
      "\n",
      "[[0 0 6]\n",
      " [0 0 2]\n",
      " [0 0 2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix = evaluate(articles_validation, features_validation, labels_validation, 'matrix')\n",
    "report = evaluate(articles_validation, features_validation, labels_validation, 'report')\n",
    "print(report)\n",
    "print(confusion_matrix)\n",
    "seaborn.heatmap(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce19dfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
