{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.feature_extraction\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import spacy\n",
    "np.random.seed(500)\n",
    "nlp = spacy.load(\"fr_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"train_disjoint.csv\" # \"datasets/articles/train_text_dataset.csv\"\n",
    "TEST_PATH = \"test_disjoint.csv\"# \"datasets/articles/test_text_dataset.csv\"\n",
    "\n",
    "fields = [\"label\", \"article\"]\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH, usecols=fields)\n",
    "test_df = pd.read_csv(TEST_PATH, usecols=fields)\n",
    "\n",
    "def cleansing(doc):\n",
    "    # Remove stop words\n",
    "    doc = [token for token in doc if not token.is_stop]\n",
    "    return doc\n",
    "\n",
    "def keep_specific_pos(doc, pos=[\"ADV\", \"ADJ\", \"VERB\", \"NOUN\"]):\n",
    "    doc = [token for token in doc if token.pos_ in pos]\n",
    "    return doc\n",
    "\n",
    "def preprocess(data):\n",
    "    docs = list(nlp.pipe(data))\n",
    "    preprocess_docs = [keep_specific_pos(cleansing(doc)) for doc in docs]\n",
    "    # Doc -> Text (+ lemmatization)\n",
    "    output_texts = [\" \".join([token.lemma_ for token in doc]) for doc in preprocess_docs]\n",
    "    return output_texts\n",
    "\n",
    "x_train = preprocess([str(text) for text in train_df[\"article\"].values])\n",
    "x_test = preprocess([str(text) for text in test_df[\"article\"].values])\n",
    "y_train, y_test = train_df[\"label\"].values - 1, test_df[\"label\"].values - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making class names shorter\n",
    "class_names = [\"true\", \"biased\", \"fake\"]\n",
    "print(','.join(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\n",
    "train_vectors = vectorizer.fit_transform(x_train)\n",
    "test_vectors = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB(alpha=.01)\n",
    "nb.fit(train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = nb.predict(test_vectors)\n",
    "sklearn.metrics.f1_score(y_test, pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_text\n",
    "from sklearn.pipeline import make_pipeline\n",
    "c = make_pipeline(vectorizer, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c.predict_proba([x_train[0]]).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer(class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "exp = explainer.explain_instance(x_train[idx], c.predict_proba, num_features=6, labels=[0, 1, 2])\n",
    "print('Document id: %d' % idx)\n",
    "print('Predicted class =', class_names[nb.predict(test_vectors[idx]).reshape(1,-1)[0,0]])\n",
    "print('True class: %s' % class_names[y_test[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Explanation for class %s' % class_names[0])\n",
    "print ('\\n'.join(map(str, exp.as_list(label=0))))\n",
    "print ()\n",
    "print ('Explanation for class %s' % class_names[1])\n",
    "print ('\\n'.join(map(str, exp.as_list(label=1))))\n",
    "print ()\n",
    "print ('Explanation for class %s' % class_names[2])\n",
    "print ('\\n'.join(map(str, exp.as_list(label=2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(x_test[idx], c.predict_proba, num_features=6, top_labels=2)\n",
    "print(exp.available_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook(text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook(text=x_test[idx], labels=(2,))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9cb844472113827ce6bd2403b167713163b10875d7f475488cf215bdab03c8f6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
