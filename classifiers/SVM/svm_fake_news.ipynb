{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words - Count occurences\n",
    "- Preprocessing : Top-k, SpaCy \n",
    "- Classifier : SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "import spacy_transformers\n",
    "import torch\n",
    "from spacy import displacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_dep_news_trf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_useless(paragraph_ann):\n",
    "    content = paragraph_ann[\"content\"]\n",
    "    paragraphs_to_delete = []\n",
    "    entities_to_delete = []\n",
    "\n",
    "    for index, paragraph in enumerate(content) :\n",
    "        if 'label' in paragraph.keys() and paragraph[\"label\"]==0:\n",
    "            paragraphs_to_delete.append(index)\n",
    "\n",
    "        else :\n",
    "            if type(paragraph[\"content\"])==list:\n",
    "              for index_entity, entity_content in enumerate(paragraph[\"content\"]):\n",
    "                if type(entity_content) == dict and 'label' in entity_content.keys() and entity_content[\"label\"]==0:\n",
    "                      entities_to_delete.append((index, index_entity))\n",
    "\n",
    "    for i in range(-1, -len(entities_to_delete)-1, -1) :\n",
    "      index, index_entity = entities_to_delete[i]\n",
    "      del paragraph_ann['content'][index]['content'][index_entity]\n",
    "\n",
    "    for index in reversed(paragraphs_to_delete):\n",
    "      del paragraph_ann['content'][index]\n",
    "\n",
    "    return paragraph_ann\n",
    "\n",
    "\n",
    "def fusion(paragraph_ann):\n",
    "  label = paragraph_ann['label']\n",
    "  author = paragraph_ann['author']\n",
    "  title = paragraph_ann['title']\n",
    "  date = paragraph_ann['date']\n",
    "  content = \"\"\n",
    "  for paragraph in paragraph_ann['content']:\n",
    "    if type(paragraph['content']) == str :\n",
    "      content += paragraph['content']\n",
    "    elif type(paragraph['content']) == list :\n",
    "      for entity in paragraph['content']:\n",
    "        content += entity['content']\n",
    "  json = {\n",
    "    'label' : label, \n",
    "    'date': date,\n",
    "    'title': title,\n",
    "    'author': author,\n",
    "    'content' : content,\n",
    "  }\n",
    "  return json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411, 2)\n"
     ]
    }
   ],
   "source": [
    "# assign directory\n",
    "ANNOTATIONS_FOLDER = 'C:\\\\Users\\\\louis\\\\Desktop\\\\NLP\\\\fake_news\\\\annotations'\n",
    "dataset = []\n",
    " \n",
    "# iterate over files in\n",
    "# that directory\n",
    "for filename in os.listdir(ANNOTATIONS_FOLDER):\n",
    "    f = os.path.join(ANNOTATIONS_FOLDER, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        with open(f, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            if data[\"label\"] > 0:\n",
    "                data = fusion(remove_useless(data))\n",
    "                dataset += [(data[\"label\"], data[\"content\"])]\n",
    "\n",
    "dataset = np.array(dataset, dtype=str)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset)\n",
    "y_train, x_train = np.array(train[:,0], dtype=int), np.array(train[:,1], dtype=str)\n",
    "y_test, x_test = np.array(test[:, 0], dtype=int), np.array(test[:,1], dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic cleansing\n",
    "def cleansing(doc):\n",
    "    # Remove stop words\n",
    "    doc = [token for token in doc if not token.is_stop]\n",
    "    return doc\n",
    "\n",
    "def keep_specific_pos(doc, pos=[\"ADV\", \"ADJ\", \"VERB\", \"NOUN\"]):\n",
    "    doc = [token for token in doc if token.pos_ in pos]\n",
    "    return doc\n",
    "\n",
    "def preprocess(data):\n",
    "    docs = list(nlp.pipe(data))\n",
    "    preprocess_docs = [keep_specific_pos(cleansing(doc)) for doc in docs]\n",
    "    # Doc -> Text (+ lemmatization)\n",
    "    output_texts = [\" \".join([token.lemma_ for token in doc]) for doc in preprocess_docs]\n",
    "    return output_texts\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'string' has incorrect type (expected str, got numpy.str_)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14884/831291042.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14884/161758452.py\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mdocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mpreprocess_docs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeep_specific_pos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleansing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Doc -> Text (+ lemmatization)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[0m\n\u001b[0;32m   1576\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mpipe\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpipes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1577\u001b[0m                 \u001b[0mdocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1578\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1579\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1597\u001b[0m ) -> Iterator[\"Doc\"]:\n\u001b[0;32m   1598\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pipe\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m         \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m         \u001b[1;31m# We added some args for pipe that __call__ doesn't expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\pipe.pyx\u001b[0m in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1597\u001b[0m ) -> Iterator[\"Doc\"]:\n\u001b[0;32m   1598\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pipe\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m         \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m         \u001b[1;31m# We added some args for pipe that __call__ doesn't expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\pipe.pyx\u001b[0m in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1597\u001b[0m ) -> Iterator[\"Doc\"]:\n\u001b[0;32m   1598\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pipe\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m         \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m         \u001b[1;31m# We added some args for pipe that __call__ doesn't expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\transition_parser.pyx\u001b[0m in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mminibatch\u001b[1;34m(items, size)\u001b[0m\n\u001b[0;32m   1546\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1547\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1548\u001b[1;33m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1549\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1597\u001b[0m ) -> Iterator[\"Doc\"]:\n\u001b[0;32m   1598\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pipe\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m         \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m         \u001b[1;31m# We added some args for pipe that __call__ doesn't expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx\u001b[0m in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mminibatch\u001b[1;34m(items, size)\u001b[0m\n\u001b[0;32m   1546\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1547\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1548\u001b[1;33m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1549\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1597\u001b[0m ) -> Iterator[\"Doc\"]:\n\u001b[0;32m   1598\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pipe\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m         \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m         \u001b[1;31m# We added some args for pipe that __call__ doesn't expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\spacy_transformers\\pipeline_component.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(self, stream, batch_size)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m    207\u001b[0m         \u001b[0minstall_extensions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mouter_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m             \u001b[0mouter_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouter_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_by_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouter_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"max_batch_items\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mminibatch\u001b[1;34m(items, size)\u001b[0m\n\u001b[0;32m   1546\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1547\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1548\u001b[1;33m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1549\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1573\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1574\u001b[0m             \u001b[1;31m# if n_process == 1, no processes are forked.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1575\u001b[1;33m             \u001b[0mdocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1576\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mpipe\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpipes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1577\u001b[0m                 \u001b[0mdocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m_ensure_doc\u001b[1;34m(self, doc_like)\u001b[0m\n\u001b[0;32m   1089\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdoc_like\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1091\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_like\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1092\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE866\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_like\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mmake_doc\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1082\u001b[0m                 \u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE088\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m             )\n\u001b[1;32m-> 1084\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1085\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_ensure_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_like\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDoc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument 'string' has incorrect type (expected str, got numpy.str_)"
     ]
    }
   ],
   "source": [
    "x = preprocess(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb doc: 308\n"
     ]
    }
   ],
   "source": [
    "print(f'Nb doc: {len(x)}')\n",
    "\n",
    "count_vec = CountVectorizer()\n",
    "count = count_vec.fit_transform(x)\n",
    "count = count.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Vocabulary: 13912\n"
     ]
    }
   ],
   "source": [
    "print('Number of Vocabulary: %d'% (len(count_vec.get_feature_names_out())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too much vocabulary : we need to remove the non-relevant ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, we have to remove the less important features (words) in order to restrain the number of vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 10000\n"
     ]
    }
   ],
   "source": [
    "# Select K best\n",
    "\n",
    "LIMIT_VOCABULARY = 10000 # K\n",
    "mask = np.argsort(np.sum(count, axis=0))[-LIMIT_VOCABULARY:]\n",
    "words_as_features = count_vec.get_feature_names_out()[mask]\n",
    "count_features = count[:, mask]\n",
    "\n",
    "print(f'Features: {len(words_as_features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][1 1 1 1 3 3 3 1 2 2 1 2 1 1 1 2 1 1 1 3 1 1 1 3 1 1 3 2 1 3 3 3 3 2 1 3 1\n",
      " 2 1 1 3 3 1 1 3 1 3 1 3 1 1 3 1 1 1 1 3 1 3 1 2 3 3 1 2 1 1 3 1 1 1 3 1 1\n",
      " 2 1 3 1 1 1 1 1 1 1 3 1 1 2 3 1 1 1 1 1 1 1 3 3 1 2 1 3 3 3 3 1 1 1 1 1 1\n",
      " 1 2 1 3 3 1 1 2 3 2 1 1 1 2 1 1 1 1 3 1 1 1 3 2 1 2 3 2 1 1 1 3 1 1 1 1 1\n",
      " 1 2 3 1 1 1 1 3 1 2 3 1 2 2 3 3 3 1 3 1 1 3 3 2 3 2 1 1 1 3 1 1 3 1 1 1 1\n",
      " 1 1 1 3 1 1 1 2 1 1 1 1 1 3 1 2 1 3 1 2 1 1 2 3 3 3 1 1 1 1 1 1 1 1 1 1 1\n",
      " 3 1 1 1 1 1 3 1 1 1 2 1 1 1 2 1 1 1 1 3 1 3 1 1 1 3 1 1 1 1 3 1 1 1 3 1 1\n",
      " 1 1 1 1 1 1 1 2 1 1 1 1 3 1 1 1 1 3 1 1 1 2 1 3 1 2 1 3 1 1 3 1 1 3 1 3 1\n",
      " 3 1 1 3 1 3 3 3 2 3 1 1]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cl = SVC(verbose=True)\n",
    "cl.fit(count, y_train)\n",
    "print(y_train)\n",
    "\n",
    "count_test = count_vec.transform(x_test).toarray()\n",
    "print(count_test)\n",
    "y_predicted = cl.predict(count_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_positives(predicted_labels, labels):\n",
    "    return np.count_nonzero(labels[predicted_labels == 1])\n",
    "\n",
    "def false_positives(predicted_labels, labels):\n",
    "    return np.count_nonzero(1 - labels[predicted_labels == 1])\n",
    "\n",
    "def true_negatives(predicted_labels, labels):\n",
    "    return np.count_nonzero(1 - labels[predicted_labels == 0])\n",
    "\n",
    "def false_negatives(predicted_labels, labels):\n",
    "    return np.count_nonzero(labels[predicted_labels == 0])\n",
    "\n",
    "class Scores:\n",
    "    def __init__(self, predicted_labels, labels):\n",
    "        self.predicted_labels = predicted_labels\n",
    "        self.labels = labels\n",
    "\n",
    "        self.tp = true_positives(self.predicted_labels, self.labels)\n",
    "        self.fp = false_positives(self.predicted_labels, self.labels)\n",
    "        self.tn = true_negatives(self.predicted_labels, self.labels)\n",
    "        self.fn = false_negatives(self.predicted_labels, self.labels)\n",
    "\n",
    "    def __repr__(self):\n",
    "        print(\"===================\\n\")\n",
    "\n",
    "        print(f\"TP : { self.tp }\")\n",
    "        print(f\"FP : { self.fp }\")\n",
    "        print(f\"TN : { self.tn }\")\n",
    "        print(f\"FN : { self.fn }\\n\")\n",
    "\n",
    "        print(\"===================\\n\")\n",
    "\n",
    "        print(f\"P : { self.positives() }\")\n",
    "        print(f\"N : { self.negatives() }\")\n",
    "        print(f\"TPR : { self.tp_rate() }\")\n",
    "        print(f\"TNR : { self.tn_rate() }\")\n",
    "        print(f\"FPR : { self.fp_rate() }\")\n",
    "        print(f\"ACC : { self.acc() }\")\n",
    "        print(f\"Precision : { self.precision() }\")\n",
    "        print(f\"NPV : { self.npv() }\")\n",
    "        print(f\"MCC : { self.mcc() }\")\n",
    "        print(f\"F1-score : { self.f_score(1) }\")\n",
    "        print(f\"Kappa : { self.kappa() } \\n\")\n",
    "\n",
    "        print(\"===================\")\n",
    "\n",
    "        return \"\"\n",
    "\n",
    "    def positives(self):\n",
    "        return self.tp + self.fn\n",
    "\n",
    "    def negatives(self):\n",
    "        return self.fp + self.tn\n",
    "\n",
    "    def tp_rate(self):\n",
    "        positives = self.positives()\n",
    "        if positives > 0:\n",
    "            return self.tp / positives\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def tn_rate(self):\n",
    "        negatives = self.negatives()\n",
    "        if negatives > 0:\n",
    "            return self.tn / negatives\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def fp_rate(self):\n",
    "        negatives = self.negatives()\n",
    "        if negatives > 0:\n",
    "            return self.fp / negatives\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def acc(self):\n",
    "        return (self.tp + self.tn) / (self.negatives() + self.positives())\n",
    "\n",
    "    def precision(self):\n",
    "        den = self.tp + self.fp\n",
    "        if den > 0:\n",
    "            return self.tp / den\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def npv(self):\n",
    "        den = self.tn + self.fn\n",
    "        if den > 0:\n",
    "            return self.tn / den\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def mcc(self):\n",
    "        den = ((self.tp + self.fp)*(self.tp + self.fn)*(self.tn + self.fp)*(self.tn + self.fn)) ** 0.5\n",
    "        if den != 0:\n",
    "            return (self.tp * self.tn - self.fp * self.fn) / den\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def f_score(self, beta):\n",
    "        precision = self.precision()\n",
    "        tpr = self.tp_rate()\n",
    "\n",
    "        if precision is None or tpr is None:\n",
    "            return None\n",
    "        return (1 + beta ** 2) * (self.precision() * self.tp_rate()) / ((beta ** 2) * self.precision() + self.tp_rate())\n",
    "\n",
    "    def kappa(self):\n",
    "        den = (self.tp + self.fp) * (self.fp + self.tn) + (self.tp + self.fn)*(self.fn + self.tn)\n",
    "        if den != 0:\n",
    "            return 2 * (self.tp * self.tn - self.fn * self.fp) / den\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = np.array(y_predicted, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "\n",
      "TP : 103\n",
      "FP : 49\n",
      "TN : 0\n",
      "FN : 0\n",
      "\n",
      "===================\n",
      "\n",
      "P : 103\n",
      "N : 49\n",
      "TPR : 1.0\n",
      "TNR : 0.0\n",
      "FPR : 1.0\n",
      "ACC : 0.6776315789473685\n",
      "Precision : 0.6776315789473685\n",
      "NPV : None\n",
      "MCC : None\n",
      "F1-score : 0.807843137254902\n",
      "Kappa : 0.0 \n",
      "\n",
      "===================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = Scores(y_predicted, y_test)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4dbaf2831e8e334ba6d9e3c076078f6f7e1ded0711c49aea2fdce3d1f94a2856"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
