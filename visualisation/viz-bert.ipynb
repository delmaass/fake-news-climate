{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for visualizing vocabulary embeddings, position embeddings, and contextualized embeddings using pretrained language representation models like BERT. The notebook uses bert-large-uncased-whole-word-masking.\n",
    " \n",
    "Uses HuggingFace transformers, t-SNE from sklearn, and adjustText (https://github.com/Phlya/adjustText). \n",
    " \n",
    "When visualizing the vocabulary embeddings, the notebook uses 10,000 embeddings from the vocab (selected with hardcoded indices to avoid unused entries and most single-character subword units) to compute the visualization, then plots a subset of size 4,000.\n",
    " \n",
    "For contextualized embeddings, the notebook computes embeddings from the final layer of BERT when run on sentences containing the same word type. Included with this notebook is a file containing 15,000 instances of the word \"values\" drawn from Wikipedia and books from Project Gutenberg. After running t-SNE on all 15,000, 750 instances are plotted with their partial sentence contexts. \n",
    "\n",
    "Finally, the absolute position embeddings are visualized by running t-SNE on the full set. \n",
    " \n",
    "Note: we often use more instances when running t-SNE than we do for visualization. This can help t-SNE to  produce a better transformation of the data.\n",
    "\n",
    "Kevin Gimpel\n",
    "\n",
    "2020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [100, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# Load BERT.\n",
    "model = BertModel.from_pretrained('bert-large-uncased-whole-word-masking')\n",
    "# Set the model to eval mode.\n",
    "model.eval()\n",
    "# This notebook assumes CPU execution. If you want to use GPUs, put the model on cuda and modify subsequent code blocks.\n",
    "#model.to('cuda')\n",
    "# Load tokenizer.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the BERT vocabulary to a file -- by default it will name this file \"vocab.txt\".\n",
    "tokenizer.save_vocabulary(vocab_path='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get BERT's vocabulary embeddings.\n",
    "wordembs = model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the vocabulary embeddings to numpy.\n",
    "allinds = np.arange(0,model.config.vocab_size,1)\n",
    "inputinds = torch.LongTensor(allinds)\n",
    "bertwordembs = wordembs(inputinds).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertwordembs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadLines(filename):\n",
    "    print(\"Loading lines from file\", filename)\n",
    "    f = open(filename,'r')\n",
    "    lines = np.array([])\n",
    "    for line in f:\n",
    "        lines = np.append(lines, line.rstrip())\n",
    "    print(\"Done. \", len(lines),\" lines loaded!\")\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertwords = loadLines('vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine vocabulary to use for t-SNE/visualization. The indices are hard-coded based partially on inspection:\n",
    "bert_char_indices_to_use = np.arange(999, 1063, 1)\n",
    "bert_voc_indices_to_plot = np.append(bert_char_indices_to_use, np.arange(1996, 5932, 1))\n",
    "bert_voc_indices_to_use = np.append(bert_char_indices_to_use, np.arange(1996, 11932, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bert_voc_indices_to_plot))\n",
    "print(len(bert_voc_indices_to_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bertwords[bert_voc_indices_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_voc_indices_to_use_tensor = torch.LongTensor(bert_voc_indices_to_use)\n",
    "bert_word_embs_to_use = wordembs(bert_voc_indices_to_use_tensor).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run t-SNE on the BERT vocabulary embeddings we selected:\n",
    "mytsne_words = TSNE(n_components=2,early_exaggeration=12,verbose=2,metric='cosine',init='pca',n_iter=2500)\n",
    "bert_word_embs_to_use_tsne = mytsne_words.fit_transform(bert_word_embs_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_words_to_plot = bertwords[bert_voc_indices_to_plot]\n",
    "print(len(bert_words_to_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the transformed BERT vocabulary embeddings:\n",
    "fig = plt.figure()\n",
    "alltexts = list()\n",
    "for i, txt in enumerate(bert_words_to_plot):\n",
    "    plt.scatter(bert_word_embs_to_use_tsne[i,0], bert_word_embs_to_use_tsne[i,1], s=0)\n",
    "    currtext = plt.text(bert_word_embs_to_use_tsne[i,0], bert_word_embs_to_use_tsne[i,1], txt, family='sans-serif')\n",
    "    alltexts.append(currtext)\n",
    "    \n",
    "\n",
    "# Save the plot before adjusting.\n",
    "plt.savefig('viz-bert-voc-tsne10k-viz4k-noadj.pdf', format='pdf')\n",
    "print('now running adjust_text')\n",
    "# Using autoalign often works better in my experience, but it can be very slow for this case, so it's false by default below:\n",
    "#numiters = adjust_text(alltexts, autoalign=True, lim=50)\n",
    "numiters = adjust_text(alltexts, autoalign=False, lim=50)\n",
    "print('done adjust text, num iterations: ', numiters)\n",
    "plt.savefig('viz-bert-voc-tsne10k-viz4k-adj50.pdf', format='pdf')\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will visualize contextualized embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function loads lines from a file, tokenizes them, and processes lines containing keyword, \n",
    "# up to a limit of maxLines lines. \n",
    "# It returns both the tokenized lines and the integer positions in those tokenized lines of the keyword.\n",
    "def loadAndTokenizeLinesAndFindKeyword(filename, keyword, maxLines):\n",
    "    print(\"Loading lines from file\", filename)\n",
    "    f = open(filename,'r')\n",
    "    lines = []\n",
    "    keywordIndices = []\n",
    "    numSkipped = 0\n",
    "    for line in f:\n",
    "        # Tokenize input\n",
    "        lineForBERT = \"[CLS] \" + line.rstrip() + \" [SEP]\"\n",
    "        tokenized_text = tokenizer.tokenize(lineForBERT)\n",
    "        if keyword in tokenized_text:\n",
    "            keywordIndex = tokenized_text.index(keyword)\n",
    "            lines.append(tokenized_text)\n",
    "            keywordIndices.append(keywordIndex)\n",
    "            if len(lines) >= maxLines:\n",
    "                break\n",
    "        else:\n",
    "            print(\"Keyword \\\"\", keyword, \"\\\" not found in line: \", tokenized_text)\n",
    "            numSkipped += 1\n",
    "    print(\"Done. \", len(lines),\" lines loaded, \", numSkipped, \" lines skipped.\")\n",
    "    return lines, keywordIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywordLines, keywordIndices = loadAndTokenizeLinesAndFindKeyword(\"values.books-wiki.15k.txt\", \"values\", 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will use BERT to encode the sentences we loaded and save the embeddings from the final layer \n",
    "# at the position of the keyword.\n",
    "embs = np.empty((0,model.config.hidden_size), float)\n",
    "# Go through all tokenized lines and keyword indices:\n",
    "for tok, ind in zip(keywordLines, keywordIndices):\n",
    "    #print(tok, ind)\n",
    "    # Convert token to vocabulary indices\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tok)\n",
    "    # segments_ids will hold indices associated with the first and second sentences in BERT.\n",
    "    # We just use sentence A indices for all tokens:\n",
    "    segments_ids = [0] * len(tok)\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    # Compute hidden states for each layer:\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "        # The first element of the output holds the hidden states of the last layer of BERT.\n",
    "        encoded_layers = outputs[0]\n",
    "        # encoded_layers has shape (batch size, sequence length, model hidden dimension)\n",
    "        assert tuple(encoded_layers.shape) == (1, len(indexed_tokens), model.config.hidden_size)\n",
    "        # Get the hidden state for the keyword position, convert it to a numpy array, and add it to the embs matrix.\n",
    "        embs = np.append(embs, [encoded_layers[0][ind][:].squeeze().numpy()], axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run t-SNE on the contextualized embeddings:\n",
    "mytsne_tokens = TSNE(n_components=2,early_exaggeration=12,verbose=2,metric='cosine',init='pca',n_iter=2500)\n",
    "embs_tsne = mytsne_tokens.fit_transform(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of strings to plot; these will be the keyword with partial context to either side.\n",
    "keywordWithContext = []\n",
    "# The window size is the (max) number of subword units on either side of the keyword to display.\n",
    "windowSize = 5\n",
    "# The following flag determines whether to merge partial-word units into single words when displaying the context.\n",
    "mergeSubwordUnits = True\n",
    "# The following flag determines whether to remove BERT boundary tokens like [CLS] and [SEP] when displaying the context.\n",
    "removeBoundaryTokens = True\n",
    "for txt, ind in zip(keywordLines, keywordIndices):\n",
    "    startInd = ind - windowSize\n",
    "    if startInd < 0:\n",
    "        startInd = 0\n",
    "    currKeywordWithContext = \" \".join(txt[startInd:ind+windowSize+1])\n",
    "    if mergeSubwordUnits:\n",
    "        currKeywordWithContext = currKeywordWithContext.replace(\" ##\", \"\")\n",
    "        currKeywordWithContext = currKeywordWithContext.replace(\"##\", \"\")\n",
    "    if removeBoundaryTokens:\n",
    "        currKeywordWithContext = currKeywordWithContext.replace(\"[CLS] \", \"\")\n",
    "        currKeywordWithContext = currKeywordWithContext.replace(\" [SEP]\", \"\")\n",
    "    keywordWithContext.append(currKeywordWithContext)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some sample keyword + context strings\n",
    "keywordWithContext[49:58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualization, we will use only the first 750 instances.\n",
    "keywordWithContextToPlot = keywordWithContext[0:750]\n",
    "print(len(keywordWithContextToPlot))\n",
    "print(keywordWithContextToPlot[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the keyword+context strings.\n",
    "fig = plt.figure()\n",
    "alltexts = list()\n",
    "for i, txt in enumerate(keywordWithContextToPlot):\n",
    "    plt.scatter(embs_tsne[i,0], embs_tsne[i,1], s=0)\n",
    "    currtext = plt.text(embs_tsne[i,0], embs_tsne[i,1], txt, family='sans-serif')\n",
    "    alltexts.append(currtext)\n",
    "    \n",
    "plt.savefig('viz-bert-ctx-values-viz750-noadj.pdf', format='pdf')\n",
    "print('now running adjust_text')\n",
    "#numiters = adjust_text(alltexts, autoalign=True, lim=50)\n",
    "numiters = adjust_text(alltexts, autoalign=False, lim=50)\n",
    "print('done adjust text, num iterations: ', numiters)\n",
    "plt.savefig('viz-bert-ctx-values-viz750-adj.pdf', format='pdf')\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will visualize the position embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the position embedding module from the model.\n",
    "posembs = 0\n",
    "for name, module in model.named_modules():\n",
    "    if name == \"embeddings.position_embeddings\":\n",
    "        posembs = module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posembs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the position embeddings to numpy.\n",
    "pos_allinds = np.arange(0,512,1)\n",
    "pos_inputinds = torch.LongTensor(pos_allinds)\n",
    "bertposembs = posembs(pos_inputinds).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertposembs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run t-SNE on the position embeddings.\n",
    "mytsne_pos = TSNE(n_components=2,early_exaggeration=12,verbose=2,metric='cosine',init='pca',n_iter=2500)\n",
    "bertposembs_tsne = mytsne_pos.fit_transform(bertposembs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate strings corresponding to the positions.\n",
    "bertpos_strings = (['{}'.format(i) for i in range(0, 512)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a smaller figure size, plot the position embeddings.\n",
    "plt.rcParams['figure.figsize'] = [25, 15]\n",
    "fig = plt.figure()\n",
    "alltexts = list()\n",
    "for i, txt in enumerate(bertpos_strings):\n",
    "    plt.scatter(bertposembs_tsne[i,0], bertposembs_tsne[i,1], s=0)\n",
    "    currtext = plt.text(bertposembs_tsne[i,0], bertposembs_tsne[i,1], txt, family='sans-serif')\n",
    "    alltexts.append(currtext)\n",
    "    \n",
    "# We don't really need to use adjustText here since the position embeddings are well-separated and there are not too many of them.\n",
    "plt.savefig('viz-bert-pos.pdf', format='pdf')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
